<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Forward Inclusion Backward Elimination | Mohammad Arafat Hussain, PhD</title> <meta name="author" content="Mohammad Arafat Hussain, PhD"/> <meta name="description" content="Efficient Feature Selection Using Forward Inclusion Backward Elimination for Machine Learning"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://marafathussain.github.io/projects/fibe/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Mohammad Arafat </span>Hussain, PhD</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Forward Inclusion Backward Elimination</h1> <p class="post-description">Efficient Feature Selection Using Forward Inclusion Backward Elimination for Machine Learning</p> </header> <article> <p>This algorithm performs a feature selection for both regression and classification tasks using any of the following models (1) linear support vector regressor/classifier, (2) Gaussian support vector regressor/classifier, (3) Regression/random forest, (4) AdaBoost regressor/classifier with linear support vector and (5) AdaBoost regressor/classifier with decision trees. This algorithm can also use model consensus in feature selection using (1) linear support vector regressor/classifier, (2) Gaussian support vector regressor/classifier, and (3) Regression/random forest. For loss calculation as well as validation performance estimation, this algorithm comes with options of using (1) mean absolute error (MAE) (2) mean absolute percentage error (MAPE), (3) accuracy, (4) F1-score, and (5) binaryROC metrics. The <code class="language-plaintext highlighter-rouge">fibe_function</code> contains all the necessary functions to run this algorithm.</p> <h2 id="github-repo">GitHub Repo</h2> <p>[<a href="https://github.com/i3-research/fibe" target="_blank" rel="noopener noreferrer">https://github.com/i3-research/fibe</a>]</p> <h2 id="how-to-run-the-algorithm">How to Run the Algorithm</h2> <p>To run this algorithm, the following function is needed to call with appropriate parameter selection:</p> <p><code class="language-plaintext highlighter-rouge">selectedFeatures, actualScore, predictedScore, validationPerformance = fibe(feature_df, score_df, fixed_features=None, columns_names=None, task_type=None, balance=False, model_name=None, metric=None, voting_strictness=None, nFold=None, maxIter=None, verbose=True)</code></p> <p>Here,</p> <ul> <li> <code class="language-plaintext highlighter-rouge">feature_df</code> is the 2D feature matrix (supports DataFrame, Numpy Array, and List) with columns representing different features.</li> <li> <code class="language-plaintext highlighter-rouge">score_df</code> is the 1D score vector as a column (supports DataFrame, Numpy Array, and List).</li> <li> <code class="language-plaintext highlighter-rouge">fixed_features</code> Predefined features that must stay in the feature set and the FIBE algorithm does not add or remove those. Must be either a List of names to select from ‘feature_df,’ or DataFrame of features added separately to ‘feature_df.’</li> <li> <code class="language-plaintext highlighter-rouge">columns_names</code> contain the names of the features. The algorithm returns the names of the selected features from this list. If not available, then the algorithm returns the column indexes of selected features.</li> <li> <code class="language-plaintext highlighter-rouge">task_type</code> either ‘regression’ or ‘classification.’ The default is ‘regression.’</li> <li> <code class="language-plaintext highlighter-rouge">balance</code> In a binary classification task, if the data is imbalanced in terms of classes, ‘balance=True’ uses resampling to balance the data.</li> <li> <code class="language-plaintext highlighter-rouge">model_name</code> For ‘regression’ task, to choose from ‘linerSVR’, ‘gaussianSVR’, ‘RegressionForest’, ‘AdaBoostDT’, ‘AdaBoostSVR’, and ‘consensus’ (consensus using ‘linerSVR’, ‘gaussianSVR’, and ‘RegressionForest’). Default is <code class="language-plaintext highlighter-rouge">'linerSVR'</code>. For the ‘classification’ task, choose from ‘linerSVC’, ‘gaussianSVC’, ‘RandomForest’, ‘AdaBoostDT’, ‘AdaBoostSVC’, and ‘consensus’ (consensus using ‘linerSVC’, ‘gaussianSVC’, and ‘RandomForest’). The default is <code class="language-plaintext highlighter-rouge">'linerSVC'</code>.</li> <li> <code class="language-plaintext highlighter-rouge">metric</code> For the <code class="language-plaintext highlighter-rouge">regression</code> task, choose from ‘MAE’ and ‘MAPE’. The default is ‘MAE.’ For the ‘classification’ task, choose from ‘Accuracy’, ‘F1-score’, and ‘binaryROC’. The default is <code class="language-plaintext highlighter-rouge">'Accuracy'</code>.</li> <li> <code class="language-plaintext highlighter-rouge">voting_strictness</code> The option ‘strict’ chooses those features that are selected at least 3 times in 5-fold cross-validation; the option ‘loose’ chooses those features that are selected at least 2 times in 5-fold cross-validation, and the option ‘both’ produces two sets of results, one for ‘strict’ and one for ‘loose’. The default is <code class="language-plaintext highlighter-rouge">'strict'</code>. For any random number of folds, <code class="language-plaintext highlighter-rouge">N</code>, the ‘strict’ threshold should be <code class="language-plaintext highlighter-rouge">0.6 X N</code> and the ‘loose’ threshold should be <code class="language-plaintext highlighter-rouge">0.4 X N</code>.</li> <li> <code class="language-plaintext highlighter-rouge">nFold</code> Number of folds in cross-validation. Preferred and default is <code class="language-plaintext highlighter-rouge">5</code>.</li> <li> <code class="language-plaintext highlighter-rouge">master</code> is the maximum number of iterations that the algorithm goes back and forth in forward inclusion and backward elimination in each fold. The default is <code class="language-plaintext highlighter-rouge">3</code>.</li> <li> <code class="language-plaintext highlighter-rouge">verbose</code> generates text for intermediate loss and selected feature list during iteration. The default is <code class="language-plaintext highlighter-rouge">True</code>.</li> </ul> <p>The outputs are:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">selectedFeatures</code> is the list of features if <code class="language-plaintext highlighter-rouge">columns_names</code> was not <code class="language-plaintext highlighter-rouge">None</code>. Otherwise column indexes of the selected features. For <code class="language-plaintext highlighter-rouge">voting_strictness</code> of ‘both’, <code class="language-plaintext highlighter-rouge">selectedFeatures</code> contains two sets of output as <code class="language-plaintext highlighter-rouge">[[selected features for 'strict'], [selected feature for 'loose']]</code>.</li> <li> <code class="language-plaintext highlighter-rouge">actualScore</code> is the list containing actual target scores. If <code class="language-plaintext highlighter-rouge">model_name</code> is chosen as ‘consensus’, this list has a repetition of values 3 times, to correspond to predictions by three models. For <code class="language-plaintext highlighter-rouge">voting_strictness</code> of ‘both’, <code class="language-plaintext highlighter-rouge">actualScore</code> contains two sets of output as <code class="language-plaintext highlighter-rouge">[[actual scores for 'strict'], [actual scores for 'loose']]</code>.</li> <li> <code class="language-plaintext highlighter-rouge">predictedScore</code> is the list containing predicted scores. If <code class="language-plaintext highlighter-rouge">model_name</code> is chosen as ‘consensus’, this list has 3 predictions per observation. Although 3 predictions per observation are generated here, ‘consensus’ uses an averaging of the losses for 3 predictions in decision-making. For <code class="language-plaintext highlighter-rouge">voting_strictness</code> of ‘both’, <code class="language-plaintext highlighter-rouge">predictedScore</code> contains two sets of output as <code class="language-plaintext highlighter-rouge">[[predicted scores for 'strict'], [predicted score for 'loose']]</code>.</li> <li> <code class="language-plaintext highlighter-rouge">validationPerformance</code> is a list containing validation performance in terms of chosen <code class="language-plaintext highlighter-rouge">metric</code> for <code class="language-plaintext highlighter-rouge">nFold</code> folds. For <code class="language-plaintext highlighter-rouge">voting_strictness</code> of ‘both’, <code class="language-plaintext highlighter-rouge">validationPerformance</code> contains two sets of output as <code class="language-plaintext highlighter-rouge">[[validation performance for 'strict'], [validation performance score for 'loose']]</code>.</li> </ul> <h2 id="algorithm-overview">Algorithm Overview</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/fibe.png" alt="" title="example image"> </div> </div> <div class="caption"> Fig. 1: Schematic diagram of our FIBE algorithm. </div> <h2 id="example-code">Example Code</h2> <p>An example Python file <code class="language-plaintext highlighter-rouge">main.py</code> is given. It includes example code to run one classification and one regression problem. Further, it includes examples of how to run the algorithm with predefined fixed features as well as data balancing options.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Mohammad Arafat Hussain, PhD. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>