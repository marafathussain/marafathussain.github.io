<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Mohammad Arafat Hussain, PhD</title> <meta name="author" content="Mohammad Arafat Hussain, PhD"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://marafathussain.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6D%6F%68%61%6D%6D%61%64.%68%75%73%73%61%69%6E@%63%68%69%6C%64%72%65%6E%73.%68%61%72%76%61%72%64.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-0545-5779" title="ORCID" target="_blank" rel="noopener noreferrer"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=https://scholar.google.ca/citations?user=hFwvdQcAAAAJ&amp;hl=en" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/M.-Hussain/2067311" title="Semantic Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-semantic-scholar"></i></a> <a href="https://www.researchgate.net/profile/Mohammad-Arafat-Hussain/" title="ResearchGate" target="_blank" rel="noopener noreferrer"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/marafathussain" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/hussainma" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a> <a href="https://dblp.org/pid/148/7569.html" title="DBLP" target="_blank" rel="noopener noreferrer"><i class="ai ai-dblp"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Mohammad Arafat</span> Hussain, PhD </h1> <p class="desc">Research Fellow, Boston Children's Hospital, Harvard Medical School</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/profile_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/profile_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/profile_pic-1400.webp"></source> <img src="/assets/img/profile_pic.jpeg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="profile_pic.jpeg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Children's Hospital,</p> <p>Landmark Center,</p> <p>401 Park Dr, Boston,</p> <p>MA 02115, USA</p> </div> </div> <div class="clearfix"> <p>[<a href="https://connects.catalyst.harvard.edu/Profiles/display/Person/201410" target="_blank" rel="noopener noreferrer">Harvard Catalyst Profile</a>] [<a href="https://brain.harvard.edu/hbi_connectome/mohammad-arafat-hussain/" target="_blank" rel="noopener noreferrer">HBI Connectome</a>] [<a href="https://research.childrenshospital.org/arafat" target="_blank" rel="noopener noreferrer">Boston Children’s</a>]</p> <p>I am currently a Postdoctoral Research Fellow in the <a href="https://www.fnndsc.org/" target="_blank" rel="noopener noreferrer">Fetal-Neonatal Neuroimaging Developmental Science Center</a> at Harvard Medical School, Boston, Massachusetts. My research interests lie in machine/deep learning and its application to medical image analysis.</p> <p>Previously, I worked as a Postdoctoral Research Associate in the <a href="https://www.medicalimageanalysis.com/" target="_blank" rel="noopener noreferrer">Medical Image Analysis Lab (MIAL)</a> at <a href="https://www.sfu.ca/computing.html" target="_blank" rel="noopener noreferrer">Simon Fraser University</a>, Burnaby, BC, Canada.</p> <p>I completed my Ph.D. in Biomedical Engineering at the <a href="https://bisicl.ece.ubc.ca/" target="_blank" rel="noopener noreferrer">University of British Columbia (UBC)</a>, Vancouver. In my Ph.D. project, I primarily focused on kidney cancer detection and analysis in CT using deep learning. I also completed my M.A.Sc. in Biomedical Engineering at UBC, Vancouver. My M.A.Sc. project focused on robust bone boundary localization in ultrasound to facilitate minimally invasive ultrasound-guided orthopedic surgery.</p> <p>Before joining UBC, I completed an M.Sc. and B.Sc. in Electrical and Electronic Engineering at <a href="https://www.buet.ac.bd/web/" target="_blank" rel="noopener noreferrer">Bangladesh University of Engineering &amp; Technology (BUET)</a>. During my M.Sc., I worked as a Research Engineer and developed novel ultrasound elastography techniques for breast cancer detection. I also worked as a Software Engineer in the <a href="https://research.samsung.com/srbd" target="_blank" rel="noopener noreferrer">Samsung R&amp;D Institute Bangladesh</a> after completing my B.Sc. degree.</p> </div> <div class="news"> <h2>news</h2> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Sep 12, 2024</th> <td> Awarded a competitive research grant from the [<a href="https://benchtobassinet.com/?page_id=2531" target="_blank" rel="noopener noreferrer">PCGC and CDDRC Fellows Program</a>] <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row">Jul 16, 2024</th> <td> Paper accepted in MICCAI-PRIME 2024 <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> [<a href="https://github.com/marafathussain/marafathussain.github.io/blob/source/assets/pdf/prime2024.pdf" target="_blank" rel="noopener noreferrer">Link</a>] </td> </tr> <tr> <th scope="row">May 13, 2024</th> <td> Paper accepted in Medical Engineering &amp; Physics <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> [<a href="https://www.sciencedirect.com/science/article/pii/S1350453324000808" target="_blank" rel="noopener noreferrer">Link</a>] </td> </tr> <tr> <th scope="row">Jan 10, 2023</th> <td> Paper accepted in Displays. [<a href="https://www.sciencedirect.com/science/article/pii/S0141938223000045" target="_blank" rel="noopener noreferrer">Link</a>] </td> </tr> <tr> <th scope="row">Oct 1, 2022</th> <td> Paper accepted in Computerized Medical Imaging and Graphics. [<a href="https://www.sciencedirect.com/science/article/pii/S0895611122000970" target="_blank" rel="noopener noreferrer">Link</a>] </td> </tr> </table> </div> </div> <div class="publications"> <h2>selected publications</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ASPNR</abbr></div> <div id="Kesri2024therole" class="col-sm-8"> <div class="title">The Role of Expert MRI Scores in Predicting Adverse 18-22-month Outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network Trials</div> <div class="author"> Ankush Kesri, Rina Bao, Chuan-Heng Hsiao, Rutvi Vyas, <em>Mohammad Arafat Hussain</em>, Scott McDonald, Jeanette Auman, Seetha Shankaran, Abbott Laptook, Michael Cotten, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ellen Grant, Yangming Ou' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In 7th Annual Meeting of American Society of Pediatric Neuroradiology</em> 2025 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ASPNR_abstract_2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kesri2024therole</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Role of Expert MRI Scores in Predicting Adverse 18-22-month Outcomes for Hypoxic Ischemic Encephalopathy in Neonatal Research Network Trials}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kesri, Ankush and Bao, Rina and Hsiao, Chuan-Heng and Vyas, Rutvi and Hussain, Mohammad Arafat and McDonald, Scott and Auman, Jeanette and Shankaran, Seetha and Laptook, Abbott and Cotten, Michael and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{7th Annual Meeting of American Society of Pediatric Neuroradiology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{ASPNR}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">PRIME</abbr></div> <div id="hussain2024rct" class="col-sm-8"> <div class="title">RCT: Relational Connectivity Transformer for Enhanced Prediction of Absolute and Residual Intelligence</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>In 7th International Workshop of Predictive Intelligence in Medicine (PRIME)</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/prime2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/marafathussain/RelationalConnectivityTransformer" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>This paper introduces the Relational Connectivity Transformer (RCT), a novel Graph-Transformer model designed for predicting absolute and residual full-scale intelligence quotient (FSIQ), performance IQ (PIQ), and verbal IQ (VIQ) scores from resting-state functional magnetic resonance imaging (rs-fMRI) data. Early prediction of neurocognitive impairments via IQ scores may allow for timely intervention. To this end, our RCT model leverages a relation-learning strategy from paired sample data via a novel graph-based transformer framework. Through a comprehensive comparison with state-of-the-art approaches in a 5-fold cross-validation setup, our model demonstrated superior performance. Statistical analysis confirmed the significant improvement (p &lt; 0.05) in FSIQ prediction, strengthening the efficacy of the proposed method. This work marks the first application of a Graph-Transformer in predicting IQ scores using rs-fMRI, introducing a novel learning strategy and contributing to the ongoing efforts to enhance the accuracy and reliability of human intelligence predictions based on functional brain connectivity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hussain2024rct</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{RCT: Relational Connectivity Transformer for Enhanced Prediction of Absolute and Residual Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{7th International Workshop of Predictive Intelligence in Medicine (PRIME)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer, Cham}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">MEP</abbr></div> <div id="marhamati2024patient" class="col-sm-8"> <div class="title">Patient’s Airway Monitoring during Cardiopulmonary Resuscitation using Deep Networks</div> <div class="author"> Mahmoud Marhamati, Behnam Dorri, Shima Imannezhad, <em>Mohammad Arafat Hussain</em>, Ali Asghar Neshat, Abulfazl Kakmishi, and Mohammad Momeny</div> <div class="periodical"> <em>Medical Engineering &amp; Physics</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S1350453324000808" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/mah2024a.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Cardiopulmonary resuscitation (CPR) is a crucial life-saving technique commonly administered to individuals experiencing cardiac arrest. Among the important aspects of CPR is ensuring the correct airway position of the patient, which is typically monitored by human tutors or supervisors. This study aims to utilize deep transfer learning for the detection of the patient’s correct and incorrect airway position during cardiopulmonary resuscitation. To address the challenge of identifying the airway position, we curated a dataset consisting of 198 recorded video sequences, each lasting 6-8 seconds, showcasing both correct and incorrect airway positions during mouth-to-mouth breathing and breathing with an Ambu Bag. We employed six cutting-edge deep networks, namely DarkNet19, EfficientNetB0, GoogleNet, MobileNet-v2, ResNet50, and NasnetMobile. These networks were initially pre-trained on computer vision data and subsequently fine-tuned using the CPR dataset. The validation of the fine-tuned networks in detecting the patient’s correct airway position during mouth-to-mouth breathing achieved impressive results, with the best sensitivity (98.8%), specificity (100%), and F-measure (97.2%). Similarly, the detection of the patient’s correct airway position during breathing with an Ambu Bag exhibited excellent performance, with the best sensitivity (100%), specificity (99.8%), and F-measure (99.7%).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">marhamati2024patient</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.medengphy.2024.104179}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Patient's Airway Monitoring during Cardiopulmonary Resuscitation using Deep Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Marhamati, Mahmoud and Dorri, Behnam and Imannezhad, Shima and Hussain, Mohammad Arafat and Neshat, Ali Asghar and Kakmishi, Abulfazl and Momeny, Mohammad}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Medical Engineering \&amp; Physics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104179}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">bioRxiv</abbr></div> <div id="hussain2023enhancing" class="col-sm-8"> <div class="title">Enhancing Neurocognitive Outcome Prediction in Congenital Heart Disease Patients: The Role of Brain Age Biomarkers and Beyond</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>bioRxiv</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.biorxiv.org/content/10.1101/2023.09.01.555976v1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/CHD_Neuro_2023.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>This paper aimed to investigate the predictive power of combining demographic, socioeconomic, and genetic factors with a brain MRI-based quantified measure of accelerated brain aging (referred to as deltaAGE) for neurocognitive outcomes in adolescents and young adults with Congenital Heart Disease (CHD). Our hypothesis posited that including the brain age biomarker (deltaAGE) would enhance neurocognitive outcome predictions compared to models excluding it. We conducted comprehensive analyses, including leave-one-subject-out and leave-one-group-out cross-validation techniques. Our results demonstrated that the inclusion of deltaAGE consistently improved prediction performance when considering the Pearson correlation coefficient, a preferable metric for this study. Notably, the deltaAGE-augmented models consistently outperformed those without deltaAGE across all cross-validation setups, and these correlations were statistically significant (p-value &lt; 0.05). Therefore, our hypothesis that incorporating the brain-age biomarker alongside demographic, socioeconomic, and genetic factors enhances neurocognitive outcome predictions in adolescents and young adults with CHD is supported by the findings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2023enhancing</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1101/2023.09.01.555976}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2023-02}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing Neurocognitive Outcome Prediction in Congenital Heart Disease Patients: The Role of Brain Age Biomarkers and Beyond}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{bioRxiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Cold Spring Harbor Laboratory}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Preprints</abbr></div> <div id="morshed2023ultrasound" class="col-sm-8"> <div class="title">Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies</div> <div class="author"> Abrar Morshed, Abdulla Al Shihab, Md Abrar Jahin, Md Jaber Al Nahian, Md Murad Hossain Sarker, Md Sharjis Ibne Wadud, Mohammad Istiaq Uddin, Muntequa Imtiaz Siraji, Nafisa Anjum, Sumiya Rajjab Shristy, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Preprints</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.preprints.org/manuscript/202303.0296/v3" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.preprints.org/manuscript/202303.0296/v3/download" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The COVID-19 pandemic has affected millions of people globally, with respiratory organs being strongly affected in individuals with comorbidities. Medical imaging-based diagnosis and prognosis have become increasingly popular in clinical settings to detect COVID-19 lung infections. Among various medical imaging modalities, ultrasound stands out as low-cost, mobile, and radiation-safe imaging technology. In this comprehensive review, we focus on ultrasound-based AI studies for COVID-19 detection that use public or private lung ultrasound datasets. We surveyed articles that used publicly available lung ultrasound datasets for COVID-19 and reviewed publicly available datasets and organize ultrasound-based AI studies per dataset. We analyzed and tabulated studies in several dimensions, such as data preprocessing, AI models, cross-validation, and evaluation criteria. In total, we reviewed 42 articles, where 28 articles used public datasets, and the rest used private data. Our findings suggest that ultrasound-based AI studies for the detection of COVID-19 have great potential for clinical use, especially for children and pregnant women. Our review also provides a useful summary for future researchers and clinicians who may be interested in the field.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">morshed2023ultrasound</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.20944/preprints202303.0296.v3}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprints}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Ultrasound-Based AI for COVID-19 Detection: A Comprehensive Review of Public and Private Lung Ultrasound Datasets and Studies}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Morshed, Abrar and Al Shihab, Abdulla and Jahin, Md Abrar and Al Nahian, Md Jaber and Sarker, Md Murad Hossain and Wadud, Md Sharjis Ibne and Uddin, Mohammad Istiaq and Siraji, Muntequa Imtiaz and Anjum, Nafisa and Shristy, Sumiya Rajjab and others}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Preprints}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">bioRxiv</abbr></div> <div id="hussain2023can" class="col-sm-8"> <div class="title">Can deep learning predict human intelligence from structural brain MRI?</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Danielle LaMay, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>bioRxiv</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.biorxiv.org/content/10.1101/2023.02.24.529924v1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.biorxiv.org/content/10.1101/2023.02.24.529924v1.full.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="https://github.com/i3-research/MRI-infer-neurocognition" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Can brain structure predict human intelligence? T1-weighted structural brain magnetic resonance images (sMRI) have been correlated with intelligence. Nevertheless, population-level association does not fully account for individual variability in intelligence. To address this, individual prediction studies emerge recently. However, they are mostly on predicting fluid intelligence (the ability to solve new problems). Studies are lacking to predict crystallized intelligence (the ability to accumulate knowledge) or general intelligence (fluid and crystallized intelligence combined). This study tests whether deep learning of sMRI can predict an individual subject’s verbal, comprehensive, and full-scale intelligence quotients (VIQ, PIQ, FSIQ), which reflect both fluid and crystallized intelligence. We performed a comprehensive set of 432 experiments, using different input images, six deep learning models, and two outcome settings, on 850 autistic and healthy subjects 6-64 years of age. Results show promise with statistical significance, and also open up questions inviting further future studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2023can</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1101/2023.02.24.529924}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Can deep learning predict human intelligence from structural brain MRI?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{bioRxiv}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2023--02}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Cold Spring Harbor Laboratory}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">bioRxiv</abbr></div> <div id="hussain2023influence" class="col-sm-8"> <div class="title">Influence of Demographic, Socio-economic, and Brain Structural Factors on Adolescent Neurocognition: A Correlation Analysis in the ABCD Initiative</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Grace Li, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>bioRxiv</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.biorxiv.org/content/10.1101/2023.02.24.529930v1.abstract" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.biorxiv.org/content/biorxiv/early/2023/02/27/2023.02.24.529930.full.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>The Adolescent Brain Cognitive Development (ABCD) initiative is a longitudinal study aimed at characterizing brain development from childhood through adolescence and identifying key biological and environmental factors that influence this development. The study measures neurocognitive abilities across a multidimensional array of functions, with a focus on the critical period of adolescence during which physical and socio-emotional changes occur and the structure of the cortical and white matter changes. In this study, we perform a correlation analysis to examine the linear relation of adolescent neurocognition functions with the demographic, socio-economic, and magnetic resonance imaging-based brain structural factors. The overall goal is to obtain a comprehensive understanding of how natural and nurtural factors influence adolescent neurocognition. Our results on &gt; 10,000 adolescents show many positive and negative statistical significance interrelations of different neurocognitive functions with the demographic, socioeconomic, and brain structural factors, and also open up questions inviting further future studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2023influence</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1101/2023.02.24.529930}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Influence of Demographic, Socio-economic, and Brain Structural Factors on Adolescent Neurocognition: A Correlation Analysis in the ABCD Initiative}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Li, Grace and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{bioRxiv}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2023--02}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Cold Spring Harbor Laboratory}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Preprints</abbr></div> <div id="hussain2023inferring" class="col-sm-8"> <div class="title">Inferring Neurocognition and Intelligence using Brain MRI</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>Preprints</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.preprints.org/manuscript/202302.0452/v1" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://www.preprints.org/manuscript/202302.0452/v1/download" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Brain magnetic resonance imaging (MRI) offers a unique lens to study neuroanatomic support of human neurocognition and intelligence. A core mystery is the MRI explanation of individual differences in neurocognition and intelligence. The past four decades have seen great advancement in studying this century-long mystery, but the sample size and population-level studies limit the explanation at the individual level. The recent rise of big data and artificial intelligence offers novel opportunities. Yet, data sources, harmonization, study design, and interpretation need to be carefully considered. This review aims to summarize past work, discuss rising opportunities and challenges, and facilitate further investigations on machine intelligence inferring human intelligence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2023inferring</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.20944/preprints202302.0452.v1}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprints}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inferring Neurocognition and Intelligence using Brain MRI}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Preprints}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CMIG</abbr></div> <div id="HUSSAIN2022102127" class="col-sm-8"> <div class="title">Active deep learning from a noisy teacher for semi-supervised 3D image segmentation: Application to COVID-19 pneumonia infection in CT</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Zahra Mirikharaji, Mohammad Momeny, Mahmoud Marhamati, Ali Asghar Neshat, <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank" rel="noopener noreferrer">Rafeef Garbi</a>, and <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank" rel="noopener noreferrer">Ghassan Hamarneh</a> </div> <div class="periodical"> <em>Computerized Medical Imaging and Graphics</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0895611122000970" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/cmig2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/marafathussain/ALNT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Supervised deep learning has become a standard approach to solving medical image segmentation tasks. However, serious difficulties in attaining pixel-level annotations for sufficiently large volumetric datasets in real-life applications have highlighted the critical need for alternative approaches, such as semi-supervised learning, where model training can leverage small expert-annotated datasets to enable learning from much larger datasets without laborious annotation. Most of the semi-supervised approaches combine expert annotations and machine-generated annotations with equal weights within deep model training, despite the latter annotations being relatively unreliable and likely to affect model optimization negatively. To overcome this, we propose an active learning approach that uses an example re-weighting strategy, where machine-annotated samples are weighted (i) based on the similarity of their gradient directions of descent to those of expert-annotated data, and (ii) based on the gradient magnitude of the last layer of the deep model. Specifically, we present an active learning strategy with a query function that enables the selection of reliable and more informative samples from machine-annotated batch data generated by a noisy teacher. When validated on clinical COVID-19 CT benchmark data, our method improved the performance of pneumonia infection segmentation compared to the state of the art.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">HUSSAIN2022102127</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Active deep learning from a noisy teacher for semi-supervised 3D image segmentation: Application to COVID-19 pneumonia infection in CT}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computerized Medical Imaging and Graphics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{102127}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0895-6111}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.compmedimag.2022.102127}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Mirikharaji, Zahra and Momeny, Mohammad and Marhamati, Mahmoud and Neshat, Ali Asghar and Garbi, Rafeef and Hamarneh, Ghassan}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Deep learning, Semi-supervised learning, Active learning, Segmentation, Noisy teacher, COVID-19, Pneumonia}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ASNR</abbr></div> <div id="lankalapalli2022accelerated" class="col-sm-8"> <div class="title">Accelerated Brain Aging in Congenital Heart Disease and Relation to Neurodevelopmental Outcome</div> <div class="author"> Ruhika Lankalapalli, Sheng He, James Ko, <em>Mohammad Arafat Hussain</em>, Kiho Im, Ai Wern Chung, Patric Johnston, Jane Newburger, Sarah Morton, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Yangming Ou' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In 60th Annual Meeting of the American Society of Neuroradiology</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ruhika_asnr_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lankalapalli2022accelerated</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Accelerated Brain Aging in Congenital Heart Disease and Relation to Neurodevelopmental Outcome}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lankalapalli, Ruhika and He, Sheng and Ko, James and Hussain, Mohammad Arafat and Im, Kiho and Chung, Ai Wern and Johnston, Patric and Newburger, Jane and Morton, Sarah and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{60th Annual Meeting of the American Society of Neuroradiology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{ASNR}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">Nature Conf.</abbr></div> <div id="hussain2022machine" class="col-sm-8"> <div class="title">Machine Intelligence to Predict Human Intelligence</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, Danielle LaMay, <a href="https://www.childrenshospital.org/directory/patricia-ellen-grant" target="_blank" rel="noopener noreferrer">Ellen Grant</a>, and <a href="https://www.childrenshospital.org/research/researchers/yangming-ou" target="_blank" rel="noopener noreferrer">Yangming Ou</a> </div> <div class="periodical"> <em>In AI, neuroscience and hardware: From neural to artificial systems and back again</em> 2022 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/mah_nat_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Nature_AI_Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hussain2022machine</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine Intelligence to Predict Human Intelligence}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and LaMay, Danielle and Grant, Ellen and Ou, Yangming}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{AI, neuroscience and hardware: From neural to artificial systems and back again}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Nature Conferences}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CIBM</abbr></div> <div id="momeny2021learning" class="col-sm-8"> <div class="title">Learning-to-Augment Strategy using Noisy and Denoised Data: Improving Generalizability of Deep CNN for the Detection of COVID-19 in X-ray Images</div> <div class="author"> Mohammad Momeny, Ali Asghar Neshat, <em>Mohammad Arafat Hussain</em>, Solmaz Kia, Mahmoud Marhamati, Ahmad Jahanbakhshi, and <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank" rel="noopener noreferrer">Ghassan Hamarneh</a> </div> <div class="periodical"> <em>Computers in Biology and Medicine</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0010482521004984" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/cibm2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/mohamadmomeny/Learning-to-augment-strategy" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Chest X-ray images are used in deep convolutional neural networks for the detection of COVID-19, the greatest human challenge of the 21st century. Robustness to noise and improvement of generalization are the major challenges in designing these networks. In this paper, we introduce a strategy for data augmentation using the determination of the type and value of noise density to improve the robustness and generalization of deep CNNs for COVID-19 detection. Firstly, we present a learning-to-augment approach that generates new noisy variants of the original image data with optimized noise density. We apply a Bayesian optimization technique to control and choose the optimal noise type and its parameters. Secondly, we propose a novel data augmentation strategy, based on denoised X-ray images, that uses the distance between denoised and original pixels to generate new data. We develop an autoencoder model to create new data using denoised images corrupted by the Gaussian and impulse noise. A database of chest X-ray images, containing COVID-19 positive images, normal images, and other non-COVID pneumonia images, is used to fine-tune the pre-trained networks (AlexNet, ShuffleNet, ResNet18, and GoogleNet). The proposed method has the better performance in comparison with the data augmentation approaches in terms of sensitivity (by 0.808), specificity (by 0.915), and F-Measure (by 0.737).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">momeny2021learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning-to-Augment Strategy using Noisy and Denoised Data: Improving Generalizability of Deep CNN for the Detection of COVID-19 in X-ray Images}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Momeny, Mohammad and Neshat, Ali Asghar and Hussain, Mohammad Arafat and Kia, Solmaz and Marhamati, Mahmoud and Jahanbakhshi, Ahmad and Hamarneh, Ghassan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computers in Biology and Medicine}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">CMIG</abbr></div> <div id="hussain2021learnable" class="col-sm-8"> <div class="title">Learnable Image Histograms-based Deep Radiomics for Renal Cell Carcinoma Grading and Staging</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank" rel="noopener noreferrer">Ghassan Hamarneh</a>, and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank" rel="noopener noreferrer">Rafeef Garbi</a> </div> <div class="periodical"> <em>Computerized Medical Imaging and Graphics</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0895611121000732" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/cmig_arafat_2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/marafathussain/ImHistNet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Fuhrman cancer grading and tumor-node-metastasis (TNM) cancer staging systems are typically used by clinicians in the treatment planning of renal cell carcinoma (RCC), a common cancer in men and women worldwide. Pathologists typically use percutaneous renal biopsy for RCC grading, while staging is performed by volumetric medical image analysis before renal surgery. Recent studies suggest that clinicians can effectively perform these classification tasks non-invasively by analysing image texture features of RCC from computed tomography (CT) data. However, image feature identification for RCC grading and staging often relies on laborious manual processes, which is error prone and time-intensive. To address this challenge, this paper proposes a learnable image histogram in the deep neural network framework that can learn task-specific image histograms with variable bin centers and widths. The proposed approach enables learning statistical context features from raw medical data, which cannot be performed by a conventional convolutional neural network (CNN). The linear basis function of our learnable image histogram is piece-wise differentiable, enabling back-propagating errors to update the variable bin centers and widths during training. This novel approach can segregate the CT textures of an RCC in different intensity spectra, which enables effcient Fuhrman low (I/II) and high (III/IV) grading as well as RCC low (I/II) and high (III/IV) staging. The proposed method is validated on a clinical CT dataset of 159 patients from The Cancer Imaging Archive (TCIA) database, and it demonstrates 80% and 83% accuracy in RCC grading and staging, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2021learnable</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learnable Image Histograms-based Deep Radiomics for Renal Cell Carcinoma Grading and Staging}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Computerized Medical Imaging and Graphics}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">IEEE TMI</abbr></div> <div id="hussain2021cascaded" class="col-sm-8"> <div class="title">Cascaded Localization Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation</div> <div class="author"> <em>Mohammad Arafat Hussain</em>, <a href="https://www.sfu.ca/computing/people/faculty/ghassanhamarneh.html" target="_blank" rel="noopener noreferrer">Ghassan Hamarneh</a>, and <a href="https://bisicl.ece.ubc.ca/rafeef/" target="_blank" rel="noopener noreferrer">Rafeef Garbi</a> </div> <div class="periodical"> <em>IEEE Transactions on Medical Imaging</em> 2021 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/9358223?casa_token=rxZNi4GaP-YAAAAA:vlaAvOf6J1pKBT9goM4k0cCgPyJQ9NgOg_SSzt4iAFwHINOSelv-LsPXU44-XYmkME_wsI8" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="/assets/pdf/tmi2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Kidney volume is an essential biomarker for a number of kidney disease diagnoses, for example, chronic kidney disease. Existing total kidney volume estimation methods often rely on an intermediate kidney segmentation step. On the other hand, automatic kidney localization in volumetric medical images is a critical step that often precedes subsequent data processing and analysis. Most current approaches perform kidney localization via an intermediate classification or regression step. This paper proposes an integrated deep learning approach for (i) kidney localization in computed tomography scans and (ii) segmentation-free renal volume estimation. Our localization method uses a selection-convolutional neural network that approximates the kidney inferior-superior span along the axial direction. Cross-sectional (2D) slices from the estimated span are subsequently used in a combined sagittal-axial Mask-RCNN that detects the organ bounding boxes on the axial and sagittal slices, the combination of which produces a final 3D organ bounding box. Furthermore, we use a fully convolutional network to estimate the kidney volume that skips the segmentation procedure. We also present a mathematical expression to approximate the ‘volume error’ metric from the ‘Sørensen–Dice coefficient.’ We accessed 100 patients’ CT scans from the Vancouver General Hospital records and obtained 210 patients’ CT scans from the 2019 Kidney Tumor Segmentation Challenge database to validate our method. Our method produces a kidney boundary wall localization error of  2.4mm and a mean volume estimation error of  5%.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">hussain2021cascaded</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cascaded Localization Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Medical Imaging}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Mohammad Arafat Hussain, PhD. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>